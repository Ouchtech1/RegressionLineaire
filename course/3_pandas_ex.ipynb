{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9409d8e6",
   "metadata": {},
   "source": [
    "# [Ex. 1] Data CO2\n",
    "\n",
    "##### On s'intéresse au fichier disponible à : `data/co2-data/owid-co2-data.csv` \n",
    "\n",
    "- 1 - Lire le fichier\n",
    "- 2 - S'assurer de la cohérence du type de chaque colonne\n",
    "- 3 - Classer les pays par émissions totales de CO2 (= colonne `co2`) par ordre décroissant (quelle est l'unité de la variable CO2 ?). On pourra classer les pays seulement sur 2018.\n",
    "- 4 - Classer les pays par PIB (= colonne `gdp`) par ordre décroissant. (quelle est l'unité de la variable PIB ?)\n",
    "- 5 - Classer les pays par CO2 / PIB par ordre décroissant.\n",
    "- 6 - Réaliser les top 25 pour ces 3 classements\n",
    "- 7 - Quels pays apparraissent dans deux top ? \n",
    "- 8 - Dans 3 tops ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ad484a",
   "metadata": {},
   "source": [
    "# [Ex. 2] Création de données de tests\n",
    "\n",
    "### Question 1\n",
    "\n",
    "> On veut créer un historique de ventes pour tester le code d'un future site de ecommerce - on peut le résumer dans le fichier CSV suivant :  \n",
    "\n",
    "|        timestamp | customer_id | product_id | quantity | price | revenue |\n",
    "|-----------------:|------------:|-----------:|---------:|------:|--------:|\n",
    "| 2022/12/27 13:05 |        1986 |       3456 |        4 |     5 |      20 |\n",
    "| 2022/12/27 13:05 |        1986 |       3459 |        3 |     6 |      18 |\n",
    "| 2022/12/27 13:06 |       24501 |       1242 |        2 |     4 |       8 |\n",
    "| 2022/12/27 13:12 |       48285 |       3424 |        4 |    25 |     100 |\n",
    "| 2022/12/27 13:14 |        2422 |       3456 |       10 |     5 |      50 |\n",
    "|              ... |         ... |        ... |      ... |   ... |     ... |\n",
    "\n",
    "\n",
    "- timestamp (datetime)\n",
    "- customer_id (int)\n",
    "- product_id (int)\n",
    "- quantity (int)\n",
    "- price (int)\n",
    "- revenue (int)\n",
    "\n",
    "\n",
    "De plus on souhaite que l'historique vérifie les contraintes suivantes : \n",
    "- La période va du 2022/07/01 00:00:00 au 2022/12/31 23:59:59 (inclus)\n",
    "- 100 000 transactions (lignes) \n",
    "- 4000 clients différents\n",
    "- 250 produits différents avec un prix moyen de 15 €\n",
    "- La quantité moyenne vendue par transaction est de 2.1 unités\n",
    "- Un même produit est toujours vendu au même prix\n",
    "\n",
    "**Créer un tel fichier**\n",
    "\n",
    "\n",
    "### Question 2 \n",
    "On ajoute les contraintes suivantes : \n",
    "- Lorsque l'on achète le mardi, on bénéficie d'une remise (crée une colonne discount)\n",
    "    - De 5% pour une transaction de 1 à 3 produits\n",
    "    - De 10% pour une transaction à partir de 4 produits\n",
    "- Les clients sont 50 % à faire au moins une transaction par mois sur tout la période\n",
    "- 10 % des clients font une seule transaction sur tout la période\n",
    "\n",
    "\n",
    "**Créer un tel fichier**\n",
    "\n",
    "\n",
    "### Question 3\n",
    "Ecrire une fonction `split_train_test` qui prend en argument une DataFrame `df` et un réel `test_proportion` entre 0 et 1 et renvoie deux DataFrames `train` et `test`, ayant les mêmes colonnes que `df` et se partageant ses lignes (aléatoirement et de manière mutuellement exclusive) avec les proportions `1 - test_portion` et `test_portion`\n",
    "\n",
    "\n",
    "### Question 4\n",
    "Même question, en faisant en sorte que les moyennes des variables quantitatives (ie `quantity` et `price`) des deux DataFrames `test` et `train` soient proches de celles des moyennes des variables quantitatives de `df` (moins de 10% d'écart)\n",
    "\n",
    "### Question 5\n",
    "Même question, en faisant en sorte que les histogrammes des variables quantitatives (ie `quantity` et `price`) des deux DataFrames `test` et `train` soient ressemblant à ceux des variables quantitatives de `df` (moins de 10% d'écart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2f1cbe",
   "metadata": {},
   "source": [
    "# [Ex. 3 ] Imdb dataset\n",
    "\n",
    "Le fichier `movie_metadata.csv` contient des informations au sujet de 5043 films qui ont été extraites de l'IMDB.\n",
    "\n",
    "- 1.\n",
    " - a. Quels sont les 10 réalisateurs qui ont le meilleur score (`imdb_score`) moyen ?\n",
    " - b. Quels sont les 10 pays qui ont le meilleur score (`imdb_score`) moyen ?\n",
    " \n",
    "\n",
    "- 2. \n",
    " - a. Créer une colonne par genre (columne `genres` Action, Adventure...) qui faut True si le film a ce genre renseigné et 0 sinon.\n",
    " - b. Calculer le nombre total de films par genre\n",
    " - c. Calculer l'évolution du nombre de films par genre entre 2000 et 2010\n",
    " - d. Calculer l'évolution 'Year to Year' (% d'augmentation entre année N et N+1) du nombre de films pour chaque genre.\n",
    " - e. Faire de même pour chaque pays.\n",
    " \n",
    " \n",
    "- 3. On s'intéresser seulement aux films publiés après 2000.\n",
    " - a. Calculer le prix à la minute de chaque film (à partir des colonnes `budget` et `duration`)\n",
    " - b. Quels sont tous les acteurs (renseignés dans les colonnes `actor_X_name`) qui ont joué dans les films qui ont un prix à la minute dans les 10% les plus élevés ? \n",
    "\n",
    "\n",
    "- 4. \n",
    " - a. Quels sont les réalisateurs dont les films ont la rentabilité moyenne (`gross` / `budget`) la plus élevée ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc967df9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 3891 entries, 0 to 5042\n",
      "Data columns (total 25 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   color                      3889 non-null   object \n",
      " 1   director_name              3891 non-null   object \n",
      " 2   num_critic_for_reviews     3891 non-null   float64\n",
      " 3   duration                   3891 non-null   float64\n",
      " 4   director_facebook_likes    3891 non-null   float64\n",
      " 5   actor_3_facebook_likes     3891 non-null   float64\n",
      " 6   actor_2_name               3886 non-null   object \n",
      " 7   actor_1_facebook_likes     3891 non-null   float64\n",
      " 8   gross                      3891 non-null   float64\n",
      " 9   genres                     3891 non-null   object \n",
      " 10  actor_1_name               3888 non-null   object \n",
      " 11  movie_title                3891 non-null   object \n",
      " 12  num_voted_users            3891 non-null   int64  \n",
      " 13  cast_total_facebook_likes  3891 non-null   int64  \n",
      " 14  actor_3_name               3881 non-null   object \n",
      " 15  facenumber_in_poster       3891 non-null   float64\n",
      " 16  plot_keywords              3860 non-null   object \n",
      " 17  num_user_for_reviews       3891 non-null   float64\n",
      " 18  language                   3887 non-null   object \n",
      " 19  country                    3891 non-null   object \n",
      " 20  budget                     3891 non-null   float64\n",
      " 21  title_year                 3891 non-null   float64\n",
      " 22  actor_2_facebook_likes     3891 non-null   float64\n",
      " 23  imdb_score                 3891 non-null   float64\n",
      " 24  movie_facebook_likes       3891 non-null   int64  \n",
      "dtypes: float64(12), int64(3), object(10)\n",
      "memory usage: 790.4+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/j4/956q66gs2k165hmfhd9v0y3c0000gn/T/ipykernel_2070/2286182906.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean[column].fillna(median_value, inplace=True)\n",
      "/var/folders/j4/956q66gs2k165hmfhd9v0y3c0000gn/T/ipykernel_2070/2286182906.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data_clean.drop(['aspect_ratio', 'content_rating', 'movie_imdb_link'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"../data/imdb/movie_metadata.csv\")\n",
    "\n",
    "# Suppression des lignes où les informations essentielles sont manquantes\n",
    "data_clean = data.dropna(subset=['gross', 'budget'])\n",
    "\n",
    "# Remplacer les valeurs manquantes dans les colonnes numériques par la médiane\n",
    "for column in data_clean.select_dtypes(include=['float64', 'int64']).columns:\n",
    "    median_value = data_clean[column].median()\n",
    "    data_clean[column].fillna(median_value, inplace=True)\n",
    "\n",
    "# Suppression des colonnes avec un grand nombre de valeurs manquantes ou inutiles\n",
    "data_clean.drop(['aspect_ratio', 'content_rating', 'movie_imdb_link'], axis=1, inplace=True)\n",
    "\n",
    "# Vérification finale des informations\n",
    "data_clean.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a23147b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique moyenne sur le log des recettes: 3.207787181905391\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer  # Correction de l'importation ici\n",
    "\n",
    "# Chargement des données\n",
    "data = pd.read_csv(\"../data/imdb/movie_metadata.csv\")\n",
    "# Nettoyage des données\n",
    "data = data.dropna(subset=['gross', 'budget'])\n",
    "data['log_gross'] = np.log1p(data['gross'])\n",
    "data['log_budget'] = np.log1p(data['budget'])\n",
    "\n",
    "# Sélection des caractéristiques et cible\n",
    "features = ['log_budget', 'director_facebook_likes', 'actor_1_facebook_likes', 'actor_2_facebook_likes',\n",
    "            'actor_3_facebook_likes', 'movie_facebook_likes']\n",
    "X = data[features]\n",
    "y = data['log_gross']\n",
    "\n",
    "# Préparation des données: Imputation et Standardisation\n",
    "imputer = SimpleImputer(strategy='median')  # Utilisation de l'imputation médiane\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Construction et entraînement du modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Calcul de l'erreur quadratique moyenne sur les données transformées\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print('Erreur quadratique moyenne sur le log des recettes:', mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077f0706",
   "metadata": {},
   "source": [
    "# [Ex. 4] Une question d'entretien\n",
    "\n",
    "\n",
    "Les questions suivantes ont été posées au cours de plusieurs entretiens pour des postes de Junior Data Scientists au sein d'une start-up parisienne : \n",
    "\n",
    "> On dispose d'un historique de ventes sur un site de ecommerce qui peut être résumé dans le fichier CSV suivant :  \n",
    "\n",
    "|        timestamp | customer_id | product_id | quantity | price | revenue |\n",
    "|-----------------:|------------:|-----------:|---------:|------:|--------:|\n",
    "| 2022/12/27 13:05 |        1986 |       3456 |        4 |     5 |      20 |\n",
    "| 2022/12/27 13:05 |        1986 |       3459 |        3 |     6 |      18 |\n",
    "| 2022/12/27 13:06 |       24501 |       1242 |        2 |     4 |       8 |\n",
    "| 2022/12/27 13:12 |       48285 |       3424 |        4 |    25 |     100 |\n",
    "| 2022/12/27 13:14 |        2422 |       3456 |       10 |     5 |      50 |\n",
    "|              ... |         ... |        ... |      ... |   ... |     ... |\n",
    "\n",
    "\n",
    "- timestamp (datetime)\n",
    "- customer_id (int)\n",
    "- product_id (int)\n",
    "- quantity (int)\n",
    "- price (int)\n",
    "- revenue (int)\n",
    "\n",
    "Pour chaque transaction (ie une ligne dans le fichier) ci-dessus :\n",
    "- 1. Ecrire qui une fonction qui prend en entrée la DataFrame des transactions et l'index d'une ligne (transaction) et renvoie True si la transaction a un chiffre d'affaire (colonne `revenue`) qui est dans le top 25% des transactions de la journée. Utiliser cette fonction pour flaguer ces transactions.\n",
    "\n",
    "\n",
    "- 2. Même question mais avec le mois en cours à la place de la journée\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "034aa3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../data/transactions/data.csv\")\n",
    "\n",
    "df['timestamp'] = pd.to_datetime(df[\"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e063744f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
